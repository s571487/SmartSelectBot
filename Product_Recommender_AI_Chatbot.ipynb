{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s571487/SmartSelectBot/blob/main/Product_Recommender_AI_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji09xLvKqBBd"
      },
      "source": [
        "<p> ################################################################## </p>\n",
        "<p>#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#\n",
        "<p> # This source code is adopted from Tomaz and modified for NWMSU chatbot application  &nbsp; #</p>\n",
        "<p>#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#\n",
        "<p></p>\n",
        "<p></p>\n",
        "<p> ################################################################## </p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqgaHIIWAv0E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8W6QNR3xzEO",
        "outputId": "d8809daf-040d-4b2a-b757-75347906e9a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5jQBSpUA1YJ"
      },
      "source": [
        "Requirements:\n",
        "\n",
        "1. **LangChain**: A framework for developing applications powered by language models.\n",
        "2. **LangChain-Community**: A collaborative space for sharing resources, tools, and discussions related to LangChain.\n",
        "3. **LangChain-OpenAI**: A LangChain extension providing integration with OpenAI's language models.\n",
        "4. **LangChain-Experimental**: A repository for experimental features and prototypes within the LangChain ecosystem.\n",
        "5. **Neo4j**: A graph database management system designed for handling and querying connected data.\n",
        "6. **tiktoken**: A library for tokenizing text, commonly used with language models to preprocess input and output.\n",
        "7. **yfiles_jupyter_graphs**: A library for creating and visualizing graphs and network diagrams in Jupyter notebooks.\n",
        "8. **Streamlit**: An open-source framework for building interactive, web-based applications using Python.\n",
        "9. **Localtunnel**: A tool that allows you to expose your local web server to the internet via a secure tunnel.\n",
        "10. **CTransformers** : A python wrapper for transfomer based models with essential configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e8mFtjUpsf-",
        "outputId": "eaf5b3ec-8d82-4b8a-a7d3-cdc88b5b8a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j tiktoken yfiles_jupyter_graphs streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFTCrVRKSfls",
        "outputId": "a668b17a-3f0f-47c7-a0d0-7ee155a27b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from ctransformers) (0.30.2)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (2025.1.31)\n",
            "Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ],
      "source": [
        "pip install ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQpoIlvoWU-Y",
        "outputId": "b4a19908-0a34-432c-856d-1c7cf877df36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\n"
          ]
        }
      ],
      "source": [
        "pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKRc3oenyXvO",
        "outputId": "ba9f6790-9cb8-4a2c-8f60-9d5a06a76687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 5s\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtND_fzFRNI"
      },
      "source": [
        "The provided code imports several components from different libraries, each serving a specific purpose. The `RunnableBranch`, `RunnableLambda`, `RunnableParallel`, and `RunnablePassthrough` from LangChain Core are utilities for creating complex workflows involving branching logic, function definitions, parallel execution, and straightforward data passing. For crafting prompts, `ChatPromptTemplate` and `PromptTemplate` are used to design structured inputs for language models.\n",
        "\n",
        "The `BaseModel` and `Field` from Pydantic assist in data validation and configuration, while typing utilities like `Tuple`, `List`, and `Optional` are used for type hinting in Python code. The message classes `AIMessage` and `HumanMessage` define interactions between an AI and a user. The `StrOutputParser` is employed for converting outputs into string format.\n",
        "\n",
        "The `os` module provides a way to interact with the operating system, and `Neo4jGraph` facilitates working with Neo4j databases. `TokenTextSplitter` helps in breaking down text into manageable tokens, essential for language processing. `ChatOpenAI` enables communication with OpenAI's chat models, and `LLMGraphTransformer` is used for transforming graph data with language models. For database interaction, `GraphDatabase` connects with Neo4j, and `GraphWidget` allows for the creation and visualization of graphs in Jupyter notebooks.\n",
        "\n",
        "Further, `Neo4jVector` supports storing and retrieving embeddings in Neo4j, while `OpenAIEmbeddings` provides tools for generating embeddings from OpenAI models. The `remove_lucene_chars` function cleans text by removing specific characters, ensuring data is properly formatted for Neo4j. Lastly, `ConfigurableField` allows for configurable data fields within a runnable, aiding in the customization of workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n5jFoh3cqFfH",
        "outputId": "ac9a016d-c350-41e4-be37-d3444fdbe070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# %%writefile main.py\n",
        "\n",
        "from langchain_core.runnables import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Tuple, List, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
        "\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n8hzmiPGDkr"
      },
      "source": [
        "These lines of code set environment variables for accessing the OpenAI API and a Neo4j database:\n",
        "\n",
        "- `os.environ[\"OPENAI_API_KEY\"] = \"sk-....\"` sets the API key for accessing OpenAI's services.\n",
        "- `os.environ[\"NEO4J_URI\"] = \"bolt+s://d......databases.neo4j.io:7687\"` specifies the URI for connecting to the Neo4j database.\n",
        "- `os.environ[\"NEO4J_USERNAME\"] = \"usr\"` sets the username for the Neo4j database connection.\n",
        "- `os.environ[\"NEO4J_PASSWORD\"] = \"pwd\"` sets the password for the Neo4j database connection.\n",
        "\n",
        "These environment variables are crucial for securely storing sensitive information required for connecting to external services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u-x0sDvkzApK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"#replace your OPEN_API key\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://5b1684a3.databases.neo4j.io\"#NEO4J URL\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\" #NEO4J USERNAME\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"y1guz43OpzBbI5_SydXAfUB0yiCWunao4yCbb3s6sjM\"#NEO4J PASSWORD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3SvhzJ4GIM2"
      },
      "source": [
        "This instance, stored in the variable graph, can be used to interact with the Neo4j database. The Neo4jGraph class provides methods and functionalities to execute queries, retrieve data, and manipulate the graph database, facilitating seamless integration and operations within the LangChain framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XwzkR_GOzArj",
        "outputId": "7b1e5b24-a3b4-474e-845c-d681ac249387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6e7385464d00>:1: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
            "  graph = Neo4jGraph()\n"
          ]
        }
      ],
      "source": [
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw1cepLUGWEM"
      },
      "source": [
        "This code snippet loads web pages from a list of URLs using the `WebBaseLoader` class from the `langchain_community.document_loaders` module:\n",
        "\n",
        "\n",
        "- **WebBaseLoader**: This class is used for loading web pages from URLs provided in a list. It likely uses web scraping techniques to retrieve the content from each URL.\n",
        "- **loader.requests_kwargs**: This line sets a keyword argument for the HTTP request made by the loader. `{'verify': False}` disables SSL certificate verification, which can be useful when dealing with self-signed certificates or testing environments.\n",
        "- **data = loader.load()**: This line executes the loading process, fetching the HTML content from the specified URLs and storing it in the `data` variable.\n",
        "\n",
        "This approach is helpful for gathering content from multiple web pages for further processing, such as natural language processing or content analysis, within the LangChain framework."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader([\"https://www.amazon.com\", \"https://www.phia.ai\",\n",
        "                        \"https://www.thredup.com\",\"https://www.instacart.com\",\n",
        "                        \"https://www.theyes.com\",\"https://www.shein.com\",\n",
        "                        \"https://www.stitchfix.com\", \"https://www.perryellis.com\",\n",
        "                         \"https://www.shopwithai.com\",\"https://www.walmart.com\",\n",
        "                        \"https://www.target.com\",\"https://www.bestbuy.com\",\n",
        "                        \"https://www.ebay.com\"\n",
        "                        ])\n",
        "loader.requests_kwargs = {'verify':False}\n",
        "data = loader.load()\n",
        "# print(data)"
      ],
      "metadata": {
        "id": "p8N8LBBsHfRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Fcg-eBv2AB",
        "outputId": "1f554c02-7ea8-404e-e272-534c1e3260dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7317"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(data[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "fOWYO20aLVBL",
        "outputId": "ed1fcd01-47a2-44bf-aed8-f01549f3c599"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmazon.com. Spend less. Smile more.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data[0].page_content[0:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNSNunP2Gd2c"
      },
      "source": [
        "\n",
        "\n",
        "- **TokenTextSplitter**: This class is used to split text into chunks, typically to prepare it for processing by language models or other natural language processing tasks.\n",
        "- **text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)**: Initializes an instance of `TokenTextSplitter` with a chunk size of 512 tokens and an overlap of 24 tokens between consecutive chunks.\n",
        "- **documents = text_splitter.split_documents(data)**: Splits the input `data` (presumably a collection of text documents) into chunks of the specified size and overlap, storing the resulting chunks in the `documents` variable.\n",
        "\n",
        "This approach is useful for breaking down large text documents or datasets into manageable pieces that can be processed more efficiently by downstream tasks or models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSBwTblIxmgO"
      },
      "outputs": [],
      "source": [
        "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI5DbzHLezVX",
        "outputId": "d1b8ba2f-a3bd-4e63-c11a-1f2d34da1188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Amazon.com. Spend less. Smile more.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to\n",
            "\n",
            "\n",
            "\n",
            "        Main content\n",
            "        \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      Keyboard shortcuts\n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "alt\n",
            "+\n",
            "/\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cart\n",
            "\n",
            "shift\n",
            "+\n",
            "alt\n",
            "+\n",
            "C\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Home\n",
            "\n",
            "shift\n",
            "+\n",
            "alt\n",
            "+\n",
            "H\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Orders\n",
            "\n",
            "shift\n",
            "+\n",
            "alt\n",
            "+\n",
            "O\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Show/Hide shortcuts\n",
            "\n",
            "shift\n",
            "+\n",
            "alt\n",
            "+\n",
            "Z\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "To move between items, use your keyboard's up or down arrows.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".us\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                   Delivering to Las Vegas 89101\n",
            "                \n",
            "\n",
            "                   Update location\n",
            "                \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "All\n",
            "\n",
            "\n",
            "Select the department you want to search in\n",
            "\n",
            "All Departments\n",
            "Alexa Skills\n",
            "Amazon Autos\n",
            "Amazon Devices\n",
            "Amazon Fresh\n",
            "Amazon Global Store\n",
            "Amazon Haul\n",
            "Amazon One Medical\n",
            "Amazon Pharmacy\n",
            "Amazon Resale\n",
            "Appliances\n",
            "Apps & Games\n",
            "Arts, Crafts & Sewing\n",
            "Audible Books & Originals\n",
            "Automotive Parts & Accessories\n",
            "Baby\n",
            "Beauty & Personal Care\n",
            "Books\n",
            "Cardenas\n",
            "CDs & Vinyl\n",
            "Cell Phones & Accessories\n",
            "Clothing, Shoes & Jewelry\n",
            "Women's Clothing, Shoes & Jewelry\n",
            "Men's Clothing, Shoes & Jewelry\n",
            "Girl's Clothing, Shoes & Jewelry\n",
            "Boy's Clothing, Shoes & Jewelry\n",
            "Baby Clothing, Shoes & Jewelry\n",
            "Collectibles & Fine Art\n",
            "Computers\n",
            "Credit and Payment Cards\n",
            "Digital Music\n",
            "Electronics\n",
            "Garden & Outdoor\n",
            "Gift Cards\n",
            "Grocery & Gourmet Food\n",
            "Handmade\n",
            "Health, Household & Baby Care\n",
            "Home & Business Services' metadata={'source': 'https://www.amazon.com', 'title': 'Amazon.com. Spend less. Smile more.', 'description': 'Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.', 'language': 'en-us'}\n",
            "page_content=' Cards\n",
            "Grocery & Gourmet Food\n",
            "Handmade\n",
            "Health, Household & Baby Care\n",
            "Home & Business Services\n",
            "Home & Kitchen\n",
            "Industrial & Scientific\n",
            "Just for Prime\n",
            "Kindle Store\n",
            "Luggage & Travel Gear\n",
            "Luxury Stores\n",
            "Magazine Subscriptions\n",
            "Movies & TV\n",
            "Musical Instruments\n",
            "Office Products\n",
            "Pet Supplies\n",
            "Premium Beauty\n",
            "Prime Video\n",
            "Smart Home\n",
            "Software\n",
            "Sports & Outdoors\n",
            "Subscribe & Save\n",
            "Subscription Boxes\n",
            "Tools & Home Improvement\n",
            "Toys & Games\n",
            "Under $10\n",
            "Video Games\n",
            "Whole Foods Market\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search Amazon\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "EN\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Hello, sign in\n",
            "Account & Lists\n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Returns\n",
            "& Orders\n",
            "\n",
            "\n",
            "\n",
            "0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        Cart\n",
            "        \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "All\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Amazon Haul\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Medical Care\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Alexa+\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Best Sellers\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Amazon Basics\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Music\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "New Releases\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Today's Deals\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Registry\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Prime\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Groceries\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Smart Home\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Gift Cards\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Customer Service\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pharmacy\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Books\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Amazon Home\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fashion\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Luxury Stores\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toys & Games\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sell\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Beauty & Personal Care\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Gift Shop\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Home Improvement\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sports & Outdoors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Automotive\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Computers\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Video Games\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pet Supplies\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Previous slide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Next slide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pre-loved handbagsLouis VuittonGoyardDiorGucciShop pre-loved handbags\n",
            "\n",
            "Fresh spring findsJewelryWomen's sandalsMen's shoesFragrancesShop Luxury Stores\n",
            "\n",
            "Discover Vionic shoesCasual sneakersSandalsFlats and loafersWalking sneakersShop now\n",
            "\n",
            "\n",
            "Sign in for the best experienceSign in securely\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Premium home upgradesKitchenFurnitureDecorBedding &' metadata={'source': 'https://www.amazon.com', 'title': 'Amazon.com. Spend less. Smile more.', 'description': 'Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.', 'language': 'en-us'}\n",
            "page_content='\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Premium home upgradesKitchenFurnitureDecorBedding & bathShop all\n",
            "\n",
            "Refresh your kids’ spaceNurseryBoy's roomGirl's roomPlayroomShop all\n",
            "\n",
            "Spring essentialsGrocerySpring cleaningPersonal careHealth & wellnessShop now\n",
            "\n",
            "Warm-weather car prepVehicle tune-upAccessoriesTruck add-onsCar wash suppliesShop all\n",
            "\n",
            "\n",
            "Refresh your lawn & gardenIndoor gardenFertilizer, soil & seedsWatering & morePots & plantersShop all\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Best Sellers in Clothing, Shoes & Jewelry\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Best Sellers in Computers & Accessories\n",
            "\n",
            "\n",
            "\n",
            "Go-to Mother's Day giftsHandmadeBeauty & wellnessSporty buysAll giftsShop Mother's Day\n",
            "\n",
            "Gifts for Mom at every priceUnder $20Under $50Under $100DealsShop Mother's Day\n",
            "\n",
            "Crazy-good finds from $2.99New inBest sellersSpring favesDecor upgradesShop Amazon Haul\n",
            "\n",
            "\n",
            "The graduation shopA+ giftsMajor dressesSpecial bagsStandout jewelrySee more on Shopbop\n",
            "\n",
            "\n",
            "Best Sellers in Home & Kitchen\n",
            "\n",
            "\n",
            "\n",
            "Best Sellers in Grocery & Gourmet Food\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Great gifts for MomOur Top 100+Customers' Most-LovedPremiumDealsShop Mother's Day\n",
            "\n",
            "Spring favoritesFashionBeautyDecorLawn & gardenShop all\n",
            "\n",
            "\n",
            "\n",
            "The swim shopSee more from Shopbop\n",
            "\n",
            "Brands Mom lovesSend Mom a gift card\n",
            "\n",
            "\n",
            "Best Sellers in Kitchen & Dining\n",
            "\n",
            "\n",
            "\n",
            "Best Sellers in Books\n",
            "\n",
            "\n",
            "\n",
            "Go-to Father's Day giftsTop 100+Customer lovedNew arrivalsPremium brandsShop Father's Day\n",
            "\n",
            "\n",
            "Small space solutionsShop small space furniture & décor\n",
            "\n",
            "Gifts for Dad at every priceUnder $20Under $50Under $100DealsShop Father's Day\n",
            "\n",
            "Wallet-friendly fashion findsSee more from Shopbop\n",
            "\n",
            "\n",
            "Best Sellers in Toys & Games\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                    Your recently viewed items and featured recommendations      ›    View or edit your browsing history     After viewing product detail pages, look here to find an easy way to' metadata={'source': 'https://www.amazon.com', 'title': 'Amazon.com. Spend less. Smile more.', 'description': 'Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.', 'language': 'en-us'}\n"
          ]
        }
      ],
      "source": [
        "print(documents[0])\n",
        "print(documents[1])\n",
        "print(documents[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2MEovPDGzBW"
      },
      "source": [
        "\n",
        "\n",
        "- **ChatOpenAI**: This class is used to interact with OpenAI's chat models. In this case, it's initialized with parameters like `temperature=0` and `model_name=\"gpt-3.5-turbo-0125\"`.\n",
        "- **LLMGraphTransformer**: This class is used to transform text documents into graph documents using a language model (LLM).\n",
        "- **Neo4jGraph**: This class represents a connection to a Neo4j graph database.\n",
        "\n",
        "\n",
        "The code first initializes the language model (`llm`) and the transformer (`llm_transformer`) to convert text documents (`documents`) into graph documents. Then, it initializes a `Neo4jGraph` instance (`graph`) and adds the transformed graph documents to the Neo4j database using the `add_graph_documents` method.\n",
        "\n",
        "This approach integrates natural language processing with graph database operations, enabling the creation of structured graph representations from unstructured text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DttkbLsyAza",
        "outputId": "8a1b7513-fd6a-4000-c932-dc0ddcbc010c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\") # gpt-4-0125-preview occasionally has issues\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "# Following needs to be used only first time to load the data. It took 3m 44s\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1WQB5-PYhj"
      },
      "source": [
        "**The following needs to be run for the first time when you load data into DB.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qxodjNISPSXK"
      },
      "outputs": [],
      "source": [
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwUdvx8I5208",
        "outputId": "a7867628-52eb-48eb-9ca3-b38409524682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content=' Services\n",
            "AudibleListen to Books & OriginalAudio Performances\n",
            "Box Office MojoFind MovieBox Office Data\n",
            "\n",
            "GoodreadsBook reviews& recommendations\n",
            "IMDbMovies, TV& Celebrities\n",
            "IMDbProGet Info EntertainmentProfessionals Need\n",
            "Kindle Direct PublishingIndie Digital & Print PublishingMade Easy\n",
            "\n",
            "Amazon PhotosUnlimited Photo StorageFree With Prime\n",
            "Prime Video DirectVideo DistributionMade Easy\n",
            "ShopbopDesignerFashion Brands\n",
            "\n",
            "Amazon ResaleGreat Deals onQuality Used Products \n",
            "Whole Foods MarketAmerica’s HealthiestGrocery Store\n",
            "Woot!Deals and Shenanigans\n",
            "ZapposShoes &Clothing\n",
            "RingSmart HomeSecurity Systems\n",
            "\n",
            "eero WiFiStream 4K Videoin Every Room\n",
            "BlinkSmart Securityfor Every Home\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "Neighbors App  Real-Time Crime& Safety Alerts\n",
            "\n",
            "Amazon Subscription BoxesTop subscription boxes – right to your door\n",
            "PillPackPharmacy Simplified\n",
            "Amazon RenewedLike-new productsyou can trust\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Conditions of Use Privacy Notice Consumer Health Data Privacy Disclosure Your Ads Privacy Choices © 1996-2025, Amazon.com, Inc. or its affiliates\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "' metadata={'source': 'https://www.amazon.com', 'title': 'Amazon.com. Spend less. Smile more.', 'description': 'Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.', 'language': 'en-us', 'id': '159a65f6bc2858ff4a26d3a7b95851c8'}\n",
            "nodes=[] relationships=[] source=Document(metadata={'source': 'https://www.amazon.com', 'title': 'Amazon.com. Spend less. Smile more.', 'description': 'Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.', 'language': 'en-us', 'id': '159a65f6bc2858ff4a26d3a7b95851c8'}, page_content=' Services\\nAudibleListen to Books & OriginalAudio Performances\\nBox Office MojoFind MovieBox Office Data\\n\\nGoodreadsBook reviews& recommendations\\nIMDbMovies, TV& Celebrities\\nIMDbProGet Info EntertainmentProfessionals Need\\nKindle Direct PublishingIndie Digital & Print PublishingMade Easy\\n\\nAmazon PhotosUnlimited Photo StorageFree With Prime\\nPrime Video DirectVideo DistributionMade Easy\\nShopbopDesignerFashion Brands\\n\\nAmazon ResaleGreat Deals onQuality Used Products \\nWhole Foods MarketAmerica’s HealthiestGrocery Store\\nWoot!Deals and Shenanigans\\nZapposShoes &Clothing\\nRingSmart HomeSecurity Systems\\n\\neero WiFiStream 4K Videoin Every Room\\nBlinkSmart Securityfor Every Home\\n\\n\\n\\xa0\\n\\nNeighbors App  Real-Time Crime& Safety Alerts\\n\\nAmazon Subscription BoxesTop subscription boxes – right to your door\\nPillPackPharmacy Simplified\\nAmazon RenewedLike-new productsyou can trust\\n\\xa0\\n\\n\\xa0\\n\\n\\n\\n\\nConditions of Use Privacy Notice Consumer Health Data Privacy Disclosure Your Ads Privacy Choices © 1996-2025, Amazon.com, Inc. or its affiliates\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n"
          ]
        }
      ],
      "source": [
        "print (documents[4])\n",
        "print(graph_documents[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-76PrdloHXmK"
      },
      "source": [
        "The `showGraph` function takes an optional `Cypher `query string as input (defaulting to a predefined query), establishes a connection to `Neo4j` using credentials from environment variables, executes the query to retrieve graph data, and then visualizes it using a `GraphWidget`. The widget allows interactive exploration of the graph nodes and relationships directly within the notebook environment, making it easy to analyze and understand graph structures and connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517,
          "referenced_widgets": [
            "2c814db4c48848fc96c2d6373fb2b1f1",
            "033857c710a94bb6badd0ab07298819b"
          ]
        },
        "id": "verAasH9yIu6",
        "outputId": "5e2096fb-1864-472c-f987-ac509241d664"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GraphWidget(layout=Layout(height='500px', width='100%'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c814db4c48848fc96c2d6373fb2b1f1"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# directly show the graph resulting from the given Cypher query\n",
        "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n",
        "\n",
        "def showGraph(cypher: str = default_cypher):\n",
        "    # create a neo4j session to run queries\n",
        "    driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
        "                os.environ[\"NEO4J_PASSWORD\"]))\n",
        "    session = driver.session()\n",
        "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
        "    widget.node_label_mapping = 'id'\n",
        "    #display(widget)\n",
        "    return widget\n",
        "\n",
        "showGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LSQjHkAHuTj"
      },
      "source": [
        "The `Neo4jVector.from_existing_graph()` method is used to create a vector index within a Neo4j database. It integrates embeddings from OpenAI's models, facilitating efficient search and retrieval operations based on both textual content and embedding similarities.\n",
        "\n",
        "### Key Components:\n",
        "\n",
        "- **LangChain Components**:\n",
        "  - **Neo4jVector**: This class from LangChain Community is designed to manage vector indexes within Neo4j, enabling storage and retrieval of embeddings associated with graph nodes.\n",
        "  - **OpenAIEmbeddings**: This class from LangChain OpenAI provides tools for generating embeddings using OpenAI's models.\n",
        "\n",
        "- **Initialization Parameters**:\n",
        "  - **OpenAIEmbeddings()**: Initializes the use of OpenAI's models to generate embeddings.\n",
        "  - **search_type=\"hybrid\"**: Specifies a hybrid search approach, leveraging both textual content and embedding similarities for efficient querying.\n",
        "  - **node_label=\"Document\"**: Specifies that nodes labeled \"Document\" in the Neo4j graph will store document-related information.\n",
        "  - **text_node_properties=[\"text\"]**: Defines the property name(s) within \"Document\" nodes where textual content is stored.\n",
        "  - **embedding_node_property=\"embedding\"**: Specifies the property name where embeddings are stored within the \"Document\" nodes.\n",
        "\n",
        "### Usage Scenario:\n",
        "\n",
        "This setup is useful in scenarios where you want to store and query documents based on both their textual content and their embeddings. For example, you can store documents in Neo4j, extract their embeddings using OpenAI's models, and then use this vector index to efficiently search for documents based on their semantic similarity to a given query or to other documents in the database.\n",
        "\n",
        "This approach leverages the capabilities of Neo4j for graph-based storage and retrieval, coupled with advanced embedding techniques from OpenAI, providing a powerful toolset for managing and analyzing textual data within a graph database environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "J23HXjaEzdu8"
      },
      "outputs": [],
      "source": [
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"Document\",\n",
        "    text_node_properties=[\"text\"],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U__qaE9sHtW8"
      },
      "source": [
        "\n",
        "\n",
        "### Retriever Setup:\n",
        "\n",
        "The code snippet performs the following actions:\n",
        "\n",
        "1. **Create Fulltext Index**:\n",
        "   - The `graph.query()` statement creates a fulltext index named `entity` if it does not already exist. This index is applied to nodes labeled `__Entity__` and indexes the `id` property of these nodes for efficient querying.\n",
        "\n",
        "2. **Entity Data Model**:\n",
        "   - The `Entities` class, derived from `BaseModel`, defines a structured representation for identifying information about entities extracted from text.\n",
        "   - **Names**: A list of strings representing entities such as courses, professors, requirements, or project entities found in the text.\n",
        "\n",
        "3. **Chat Prompt Template**:\n",
        "   - The `ChatPromptTemplate.from_messages()` method initializes a prompt template for interacting with users.\n",
        "   - The prompt consists of a system message informing the user about the extraction task and a human message specifying the format for input to extract information.\n",
        "\n",
        "4. **Entity Chain**:\n",
        "   - The `prompt | llm.with_structured_output(Entities)` constructs an entity extraction pipeline using LangChain:\n",
        "     - **Prompt**: Provides instructions to the user on how to input questions or text for entity extraction.\n",
        "     - **LLM (Language Model)**: Processes the input using OpenAI's language model to extract structured entities as defined by the `Entities` class.\n",
        "\n",
        "### Usage:\n",
        "\n",
        "This setup is designed to facilitate the extraction of entities from text input in a structured and systematic manner. The fulltext index ensures that entity nodes in the Neo4j graph are efficiently indexed, allowing for quick retrieval of relevant entities based on their `id` property. The `Entities` data model and the prompt template guide the interaction with users, ensuring that the extraction process is clear and consistent.\n",
        "\n",
        "This approach leverages natural language processing and graph database capabilities to manage and analyze textual data effectively, supporting tasks such as information extraction, entity linking, and knowledge base population within a broader application or system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DLAEMgHz2nF",
        "outputId": "2d6ab009-32e2-4fc6-db14-bd8771cbaad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1660: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Retriever\n",
        "\n",
        "graph.query(\n",
        "    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
        "\n",
        "# Extract entities from text\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the courses, requirements, or business entities that \"\n",
        "        \"appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting product names, categories, features, and brand entities from the user's input.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "entity_chain = prompt | llm.with_structured_output(Entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JKJNR3YWU-p"
      },
      "source": [
        "### Description\n",
        "\n",
        "This script is used to retrieve related information from a Neo4j graph database based on user input.\n",
        "\n",
        "#### Functions:\n",
        "\n",
        "- **`generate_full_text_query(input: str)`**  \n",
        "  Converts a given input string into a fuzzy full-text search query.  \n",
        "  - Splits the input into individual words.\n",
        "  - Appends a similarity threshold (`~2`) to each word to allow minor misspellings.\n",
        "  - Combines the words using the `AND` operator for more accurate matching.\n",
        "\n",
        "- **`structured_retriever(question: str)`**  \n",
        "  Extracts entities from a natural language question and fetches related nodes from the graph.  \n",
        "  - Uses `entity_chain` to extract key entity names from the question.\n",
        "  - For each entity, performs a full-text search using the generated query.\n",
        "  - Retrieves up to 50 paths showing relationships to and from each matching node.\n",
        "  - Returns the results as a formatted string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "V1jRiI6G0J6P"
      },
      "outputs": [],
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a full-text search query for a given input string.\n",
        "\n",
        "    This function constructs a query string suitable for a full-text search.\n",
        "    It processes the input string by splitting it into words and appending a\n",
        "    similarity threshold (~2 changed characters) to each word, then combines\n",
        "    them using the AND operator. Useful for mapping entities from user questions\n",
        "    to database values, and allows for some misspelings.\n",
        "    \"\"\"\n",
        "    full_text_query = \"\"\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    for word in words[:-1]:\n",
        "        full_text_query += f\" {word}~2 AND\"\n",
        "    full_text_query += f\" {words[-1]}~2\"\n",
        "    return full_text_query.strip()\n",
        "\n",
        "# Fulltext index query\n",
        "def structured_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "    for entity in entities.names:\n",
        "        response = graph.query(\n",
        "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
        "            YIELD node,score\n",
        "            CALL {\n",
        "              WITH node\n",
        "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
        "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "              UNION ALL\n",
        "              WITH node\n",
        "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
        "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
        "            }\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDRKabxJWU-q"
      },
      "source": [
        "- **`retriever(question: str)`**  \n",
        "  Combines results from both structured and unstructured data sources to answer a user question.  \n",
        "  - Logs the original search query.\n",
        "  - Uses `structured_retriever` to fetch entity-related information from a Neo4j graph (structured data).\n",
        "  - Performs a similarity search over a vector index to retrieve relevant documents (unstructured data).\n",
        "  - Formats and returns both data types in a combined response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "C1ftDuLy0P8X"
      },
      "outputs": [],
      "source": [
        "def retriever(question: str):\n",
        "    print(f\"Search query: {question}\")\n",
        "    structured_data = structured_retriever(question)\n",
        "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
        "    final_data = f\"\"\"Structured data:\n",
        "{structured_data}\n",
        "Unstructured data:\n",
        "{\"#Document \". join(unstructured_data)}\n",
        "    \"\"\"\n",
        "    return final_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_-vBRUQWU-r"
      },
      "source": [
        "### Condensing Chat History for Standalone Question Generation\n",
        "\n",
        "This code helps rephrase a follow-up question into a standalone question by considering the previous chat history.\n",
        "\n",
        "#### Components:\n",
        "\n",
        "- **`_template` and `CONDENSE_QUESTION_PROMPT`**  \n",
        "  Defines a prompt template used to generate a standalone question from a follow-up query and previous chat context.\n",
        "\n",
        "- **`_format_chat_history(chat_history: List[Tuple[str, str]]) -> List`**  \n",
        "  Converts a list of chat history (pairs of human and AI messages) into a format compatible with LLMs, using `HumanMessage` and `AIMessage` objects.\n",
        "\n",
        "- **`_search_query`**  \n",
        "  A conditional chain (`RunnableBranch`) that:\n",
        "  - If chat history exists:\n",
        "    - Formats the history.\n",
        "    - Fills the prompt with the history and the follow-up question.\n",
        "    - Sends it to an LLM (e.g., OpenAI) to generate a standalone question.\n",
        "  - If no chat history exists:\n",
        "    - Returns the original question as-is.\n",
        "\n",
        "This setup is typically used to improve retrieval or question answering pipelines by ensuring queries are self-contained.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "azltkyJN0U_I"
      },
      "outputs": [],
      "source": [
        "# Condense a chat history and follow-up question into a standalone question\n",
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
        "in its original language.\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"  # noqa: E501\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
        "\n",
        "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
        "    buffer = []\n",
        "    for human, ai in chat_history:\n",
        "        buffer.append(HumanMessage(content=human))\n",
        "        buffer.append(AIMessage(content=ai))\n",
        "    return buffer\n",
        "\n",
        "_search_query = RunnableBranch(\n",
        "    # If input includes chat_history, we condense it with the follow-up question\n",
        "    (\n",
        "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
        "            run_name=\"HasChatHistoryCheck\"\n",
        "        ),  # Condense follow-up question and chat into a standalone_question\n",
        "        RunnablePassthrough.assign(\n",
        "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
        "        )\n",
        "        | CONDENSE_QUESTION_PROMPT\n",
        "        | ChatOpenAI(temperature=0)\n",
        "        | StrOutputParser(),\n",
        "    ),\n",
        "    # Else, we have no chat history, so just pass through the question\n",
        "    RunnableLambda(lambda x : x[\"question\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpA9dhbRWU-6"
      },
      "source": [
        "### Answering a Question Using Context-Aware Retrieval\n",
        "\n",
        "This code defines a chain that answers a user question based only on retrieved context from structured and unstructured sources.\n",
        "\n",
        "#### Components:\n",
        "\n",
        "- **`template` and `prompt`**  \n",
        "  A prompt template that:\n",
        "  - Inserts the relevant context and the user's question.\n",
        "  - Instructs the model to respond in natural, concise language.\n",
        "\n",
        "- **`chain`**  \n",
        "  A composed pipeline that:\n",
        "  - Runs two parallel steps:\n",
        "    - **`_search_query | retriever`**: Uses the `_search_query` logic to condense the question (if chat history exists), and then fetches relevant context via the `retriever` function.\n",
        "    - **`RunnablePassthrough()`**: Passes the original question directly.\n",
        "  - Fills the `prompt` with the retrieved context and question.\n",
        "  - Sends the filled prompt to the language model (`llm`) to generate a response.\n",
        "  - Parses and returns the final answer as a plain string.\n",
        "\n",
        "This setup ensures that the model's response is grounded in actual retrieved knowledge, improving relevance and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Bru0C7ox0aJY"
      },
      "outputs": [],
      "source": [
        "# Answer the question based only on the following context\n",
        "template = \"\"\"Answer the query:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Use natural language and be concise.\n",
        "Answer:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"context\": _search_query | retriever,\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87XK7HSgWU-8"
      },
      "source": [
        "### `chain.invoke({\"question\": \"...\"})` — What It Does\n",
        "\n",
        "This command executes a full pipeline that answers a user’s question by retrieving relevant data from both structured and unstructured sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBOP7MYrV3Af"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "Xv4LdswWPvZe",
        "outputId": "ca2f8640-2f67-461b-f799-675eebbc4f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: I'm looking for a noise-canceling headset under $150 from Sony or Bose.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The query is unstructured data as it is a natural language question seeking specific information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"I'm looking for a noise-canceling headset under $150 from Sony or Bose.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "L5C9R3Pp0lrw",
        "outputId": "2a354486-08fb-4d7e-d99b-03fb3a66e42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Is the Apple Watch Series 9 waterproof and does it support blood oxygen monitoring?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Apple Watch Series 9 is waterproof and supports blood oxygen monitoring.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#True Positive\n",
        "chain.invoke({\"question\": \"Is the Apple Watch Series 9 waterproof and does it support blood oxygen monitoring?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en1XQ9DlWU-_"
      },
      "source": [
        "### Disabling Warnings and Setting Logging Levels for Neo4j\n",
        "\n",
        "This code snippet is used to **suppress warnings** and **set logging levels** for specific parts of the code, especially in the context of working with the Neo4j database.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QAd4_yQDRQMv"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"neo4j.notifications\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "duilHxHs1Ac9",
        "outputId": "3a9197c2-777c-4385-d253-38fc470f0cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Is the Sony WH-1000XM4 only available in red and green colors?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Sony WH-1000XM4 is available in multiple colors, not just red and green.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#True Negative\n",
        "chain.invoke({\"question\": \"Is the Sony WH-1000XM4 only available in red and green colors?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "S7CARN8C1IRB",
        "outputId": "5a5a6a2f-a7d4-411d-f10a-f4ed61067765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Is the battery life of the Bose QuietComfort 45 just 5 hours?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The battery life of the Bose QuietComfort 45 is not just 5 hours.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# False Negative\n",
        "chain.invoke({\"question\": \"Is the battery life of the Bose QuietComfort 45 just 5 hours?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FR1gMLPx1S0M",
        "outputId": "64854d36-e159-47bb-c8a1-33d50f75c0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Is 8GB RAM sufficient for running design software on a laptop?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Structured data: No specific information related to the RAM requirements for running design software on a laptop.\\n\\nUnstructured data: No relevant information related to the RAM requirements for running design software on a laptop.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# False Positives\n",
        "chain.invoke({\"question\": \"Is 8GB RAM sufficient for running design software on a laptop?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHVxM45pR1p5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DJRGvroZ1cSJ",
        "outputId": "24031d2d-7827-4318-a982-0dd73c33d365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Who is the manufacturer of the Samsung Galaxy Buds2 Pro?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The manufacturer of the Samsung Galaxy Buds2 Pro is Samsung.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"Who is the manufacturer of the Samsung Galaxy Buds2 Pro?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Q784P6LWt-ua",
        "outputId": "2caea459-29f8-4765-ef2d-c804a5b433da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: What is the customer support email for Bose?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The customer support email for Bose is not provided in the structured or unstructured data provided. It is recommended to visit the official Bose website or contact their customer support hotline for assistance.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"What is the customer support email for Bose?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "T1x2V51PuENT",
        "outputId": "3d5f060b-28ca-4290-b947-0e521c1c9171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: What are the must-have features in a gaming laptop under $1000?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Structured data: Best Sellers in Computers & Accessories\\n\\nUnstructured data: The query does not directly relate to the content provided.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"What are the must-have features in a gaming laptop under $1000?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EjgwVXmyvqmM",
        "outputId": "33520bb9-e893-46b0-e230-c7d4d607d239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Is the Kindle Paperwhite waterproof? Tell me T or F.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'False.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"Is the Kindle Paperwhite waterproof? Tell me T or F.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EIkFhW5cWU_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12d588e-44fd-468b-b8f3-94f321a778bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "from langchain_core.runnables import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Tuple, List, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
        "\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"#replace your OPEN_API key\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://5b1684a3.databases.neo4j.io\"#NEO4J URL\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\" #NEO4J USERNAME\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"y1guz43OpzBbI5_SydXAfUB0yiCWunao4yCbb3s6sjM\"#NEO4J PASSWORD\n",
        "\n",
        "_search_query = RunnableLambda(lambda x : x[\"question\"])\n",
        "\n",
        "\n",
        "graph = Neo4jGraph()\n",
        "\n",
        "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\") # gpt-4-0125-preview occasionally has issues\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"Document\",\n",
        "    text_node_properties=[\"text\"],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")\n",
        "\n",
        "\n",
        "graph.query(\n",
        "    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
        "\n",
        "# Extract entities from text\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the product names, features, specifications, brands, prices, or use cases \"\n",
        "                    \"that appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting product names, brands, features, specifications, price ranges, and use cases from the text.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following \"\n",
        "            \"input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "entity_chain = prompt | llm.with_structured_output(Entities)\n",
        "\n",
        "def generate_full_text_query(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a full-text search query for a given input string.\n",
        "\n",
        "    This function constructs a query string suitable for a full-text search.\n",
        "    It processes the input string by splitting it into words and appending a\n",
        "    similarity threshold (~2 changed characters) to each word, then combines\n",
        "    them using the AND operator. Useful for mapping entities from user questions\n",
        "    to database values, and allows for some misspelings.\n",
        "    \"\"\"\n",
        "    full_text_query = \"\"\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    for word in words[:-1]:\n",
        "        full_text_query += f\" {word}~2 AND\"\n",
        "    full_text_query += f\" {words[-1]}~2\"\n",
        "    return full_text_query.strip()\n",
        "\n",
        "# Fulltext index query\n",
        "def structured_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "    for entity in entities.names:\n",
        "        response = graph.query(\n",
        "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
        "            YIELD node,score\n",
        "            CALL {\n",
        "              WITH node\n",
        "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
        "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "              UNION ALL\n",
        "              WITH node\n",
        "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
        "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
        "            }\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result\n",
        "\n",
        "def retriever(question: str):\n",
        "    print(f\"Search query: {question}\")\n",
        "    structured_data = structured_retriever(question)\n",
        "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
        "    final_data = f\"\"\" Structured data: {structured_data} Unstructured data: {\"#Document \". join(unstructured_data)}  \"\"\"\n",
        "    return final_data\n",
        "\n",
        "\n",
        "def answerquery(question: str):\n",
        "  template = \"\"\"Answer the question based only on the following context:\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "  Use natural language and be concise.\n",
        "  Answer:\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "  chain = (\n",
        "      RunnableParallel(\n",
        "          {\n",
        "              \"context\": _search_query | retriever,\n",
        "              \"question\": RunnablePassthrough(),\n",
        "          }\n",
        "      )\n",
        "      | prompt\n",
        "      | llm\n",
        "      | StrOutputParser()\n",
        "  )\n",
        "\n",
        "  return chain.invoke(({\"question\": question}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UzFfyTKBZfoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df83761e-09cb-4773-ad00-c4d4c20da6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from main import answerquery\n",
        "\n",
        "st.title(\"AI Product Recommender Chatbot\")\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# React to user input\n",
        "if prompt := st.text_input(\"What is up?\"):\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    response = answerquery(prompt)\n",
        "    # Display assistant response in chat message container\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(response)\n",
        "    # Add assistant response to chat history\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFaxmm4cZyu9",
        "outputId": "2d757e5a-4de9-450a-b224-4481278a5a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.94.118:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c814db4c48848fc96c2d6373fb2b1f1": {
          "model_module": "yfiles-jupyter-graphs",
          "model_name": "GraphModel",
          "model_module_version": "^1.10.3",
          "state": {
            "_context_pane_mapping": [
              {
                "id": "Neighborhood",
                "title": "Neighborhood"
              },
              {
                "id": "Data",
                "title": "Data"
              },
              {
                "id": "Search",
                "title": "Search"
              },
              {
                "id": "About",
                "title": "About"
              }
            ],
            "_data_importer": "neo4j",
            "_directed": true,
            "_dom_classes": [],
            "_edges": [],
            "_graph_layout": {},
            "_highlight": [],
            "_license": {},
            "_model_module": "yfiles-jupyter-graphs",
            "_model_module_version": "^1.10.3",
            "_model_name": "GraphModel",
            "_neighborhood": {},
            "_nodes": [],
            "_overview": {
              "enabled": null,
              "overview_set": false
            },
            "_selected_graph": [
              [],
              []
            ],
            "_sidebar": {
              "enabled": false,
              "start_with": null
            },
            "_view_count": null,
            "_view_module": "yfiles-jupyter-graphs",
            "_view_module_version": "^1.10.3",
            "_view_name": "GraphView",
            "layout": "IPY_MODEL_033857c710a94bb6badd0ab07298819b"
          }
        },
        "033857c710a94bb6badd0ab07298819b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "500px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}